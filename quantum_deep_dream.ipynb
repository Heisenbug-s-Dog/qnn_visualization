{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"quantum_deep_dream.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ZgoZKWV7W1v","executionInfo":{"status":"ok","timestamp":1613666641445,"user_tz":-540,"elapsed":23050,"user":{"displayName":"JOON SUK HUH","photoUrl":"","userId":"03235780383723321017"}},"outputId":"d523296e-d316-47b2-e2d7-ddd89e17f458"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RUInxtpL88R4"},"source":["!pip install torch==1.3.1\r\n","!pip install torchvision==0.4.2\r\n","!pip install Pillow==6.2.1\r\n","!pip install pennylane==0.7.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wtz_fQE685eo","executionInfo":{"status":"ok","timestamp":1613666823546,"user_tz":-540,"elapsed":2133,"user":{"displayName":"JOON SUK HUH","photoUrl":"","userId":"03235780383723321017"}},"outputId":"9aa265ba-f124-4cb9-8b56-1844e7b4b4bd"},"source":["# OpenMP: number of parallel threads.\r\n","%env OMP_NUM_THREADS=1\r\n","\r\n","# Plotting\r\n","%matplotlib inline\r\n","import matplotlib.pyplot as plt\r\n","\r\n","# PyTorch\r\n","import torch\r\n","import torch.nn as nn\r\n","import torch.optim as optim\r\n","from torch.optim import lr_scheduler\r\n","import torchvision\r\n","from torchvision import datasets, models, transforms\r\n","\r\n","# Pennylane\r\n","import pennylane as qml\r\n","from pennylane import numpy as np\r\n","\r\n","# Other tools\r\n","import time\r\n","import copy"],"execution_count":1,"outputs":[{"output_type":"stream","text":["env: OMP_NUM_THREADS=1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VAqr-rmQ8XZH","executionInfo":{"status":"ok","timestamp":1613666826008,"user_tz":-540,"elapsed":884,"user":{"displayName":"JOON SUK HUH","photoUrl":"","userId":"03235780383723321017"}}},"source":["filtered_classes = ['cat', 'dog']  # Subset of CIFAR ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')\r\n","n_qubits = 4                       # Number of qubits\r\n","quantum = True                     # If set to \"False\", the dressed quantum circuit is replaced by \r\n","                                   # An enterily classical net (defined by the next parameter). \r\n","classical_model = '512_n'          # Possible choices: '512_n','512_nq_n','551_512_n'. [nq=n_qubits, n=num_filtered_classes]\r\n","step = 0.001                       # Learning rate\r\n","batch_size = 8                     # Number of samples for each training step\r\n","num_epochs = 3                     # Number of training epochs\r\n","q_depth = 5                        # Depth of the quantum circuit (number of variational layers)\r\n","gamma_lr_scheduler = 1             # Learning rate reduction applied every 10 epochs.                       \r\n","max_layers = 15                    # Keep 15 even if not all are used.\r\n","q_delta = 0.01                     # Initial spread of random quantum weights\r\n","rng_seed = 0                       # Seed for random number generator\r\n","start_time = time.time()           # start of the computation timer"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y3nbUaxU8qZn","executionInfo":{"status":"ok","timestamp":1613666826948,"user_tz":-540,"elapsed":860,"user":{"displayName":"JOON SUK HUH","photoUrl":"","userId":"03235780383723321017"}},"outputId":"60d8156f-6144-4fe6-d1c8-ab1e426d2476"},"source":["torch.manual_seed(rng_seed)"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f4a4417acb0>"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"LQayFKzz8ZQX","executionInfo":{"status":"ok","timestamp":1613666826948,"user_tz":-540,"elapsed":721,"user":{"displayName":"JOON SUK HUH","photoUrl":"","userId":"03235780383723321017"}}},"source":["dev = qml.device('default.qubit', wires=n_qubits)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"pkwj9T9R8bhv","executionInfo":{"status":"ok","timestamp":1613666827472,"user_tz":-540,"elapsed":1025,"user":{"displayName":"JOON SUK HUH","photoUrl":"","userId":"03235780383723321017"}}},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"z3VbxlJ18rms","executionInfo":{"status":"ok","timestamp":1613666827473,"user_tz":-540,"elapsed":843,"user":{"displayName":"JOON SUK HUH","photoUrl":"","userId":"03235780383723321017"}}},"source":["def H_layer(nqubits):\r\n","    \"\"\"Layer of single-qubit Hadamard gates. \r\n","    \"\"\"\r\n","    for idx in range(nqubits):\r\n","        qml.Hadamard(wires=idx)\r\n","        \r\n","def RY_layer(w):\r\n","    \"\"\"Layer of parametrized qubit rotations around the y axis. \r\n","    \"\"\"\r\n","    for idx, element in enumerate(w):\r\n","        qml.RY(element, wires=idx)\r\n","\r\n","def entangling_layer(nqubits):\r\n","    \"\"\"Layer of CNOTs followed by another shifted layer of CNOT.\r\n","    \"\"\"\r\n","    # In other words it should apply something like :\r\n","    # CNOT  CNOT  CNOT  CNOT...  CNOT\r\n","    #   CNOT  CNOT  CNOT...  CNOT  \r\n","    for i in range(0, nqubits - 1, 2): # Loop over even indices: i=0,2,...N-2  \r\n","        qml.CNOT(wires=[i, i + 1])\r\n","    for i in range(1, nqubits - 1,2): # Loop over odd indices:  i=1,3,...N-3\r\n","        qml.CNOT(wires=[i, i + 1])"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ziq2p-_l8vEt","executionInfo":{"status":"ok","timestamp":1613666827473,"user_tz":-540,"elapsed":710,"user":{"displayName":"JOON SUK HUH","photoUrl":"","userId":"03235780383723321017"}}},"source":["@qml.qnode(dev, interface='torch')\r\n","def q_net(q_in, q_weights_flat):\r\n","        \r\n","        # Reshape weights\r\n","        q_weights = q_weights_flat.reshape(max_layers, n_qubits)\r\n","        \r\n","        # Start from state |+> , unbiased w.r.t. |0> and |1>\r\n","        H_layer(n_qubits)\r\n","        \r\n","        # Embed features in the quantum node\r\n","        RY_layer(q_in)\r\n","       \r\n","        # Sequence of trainable variational layers\r\n","        for k in range(q_depth):\r\n","            entangling_layer(n_qubits)\r\n","            RY_layer(q_weights[k+1])\r\n","\r\n","        # Expectation values in the Z basis\r\n","        return [qml.expval(qml.PauliZ(j)) for j in range(n_qubits)]"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"fo2D1Yep8ybF","executionInfo":{"status":"ok","timestamp":1613666827951,"user_tz":-540,"elapsed":1097,"user":{"displayName":"JOON SUK HUH","photoUrl":"","userId":"03235780383723321017"}}},"source":["class Quantumnet(nn.Module):\r\n","        def __init__(self):\r\n","            super().__init__()\r\n","            self.pre_net = nn.Linear(512, n_qubits)\r\n","            self.q_params = nn.Parameter(q_delta * torch.randn(max_layers * n_qubits))\r\n","            self.post_net = nn.Linear(n_qubits, len(filtered_classes))\r\n","\r\n","        def forward(self, input_features):\r\n","            pre_out = self.pre_net(input_features) \r\n","            q_in = torch.tanh(pre_out) * np.pi / 2.0   \r\n","            \r\n","            # Apply the quantum circuit to each element of the batch, and append to q_out\r\n","            q_out = torch.Tensor(0, n_qubits)\r\n","            q_out = q_out.to(device)\r\n","            for elem in q_in:\r\n","                q_out_elem = q_net(elem,self.q_params).float().unsqueeze(0)\r\n","                q_out = torch.cat((q_out, q_out_elem))\r\n","            return self.post_net(q_out)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"b0LC1qqBEyne","executionInfo":{"status":"ok","timestamp":1613666827951,"user_tz":-540,"elapsed":1045,"user":{"displayName":"JOON SUK HUH","photoUrl":"","userId":"03235780383723321017"}}},"source":["class Quantumnet_Cut(nn.Module):\r\n","        def __init__(self):\r\n","            super().__init__()\r\n","            self.pre_net = nn.Linear(512, n_qubits)\r\n","            self.q_params = nn.Parameter(q_delta * torch.randn(max_layers * n_qubits))\r\n","\r\n","        def forward(self, input_features):\r\n","            pre_out = self.pre_net(input_features) \r\n","            q_in = torch.tanh(pre_out) * np.pi / 2.0   \r\n","            \r\n","            # Apply the quantum circuit to each element of the batch, and append to q_out\r\n","            q_out = torch.Tensor(0, n_qubits)\r\n","            q_out = q_out.to(device)\r\n","            for elem in q_in:\r\n","                q_out_elem = q_net(elem,self.q_params).float().unsqueeze(0)\r\n","                q_out = torch.cat((q_out, q_out_elem))\r\n","            return q_out"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"rAzOGdQwlWKL","executionInfo":{"status":"ok","timestamp":1613666828404,"user_tz":-540,"elapsed":1403,"user":{"displayName":"JOON SUK HUH","photoUrl":"","userId":"03235780383723321017"}}},"source":["class Quantumnet_Classical_Cut(nn.Module):\r\n","        def __init__(self):\r\n","            super().__init__()\r\n","            self.pre_net = nn.Linear(512, n_qubits)\r\n","            self.q_params = nn.Parameter(q_delta * torch.randn(max_layers * n_qubits))\r\n","\r\n","        def forward(self, input_features):\r\n","            pre_out = self.pre_net(input_features) \r\n","            q_in = torch.tanh(pre_out) * np.pi / 2.0   \r\n","\r\n","            return q_in"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"i8G4gP-780UW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613666830583,"user_tz":-540,"elapsed":3517,"user":{"displayName":"JOON SUK HUH","photoUrl":"","userId":"03235780383723321017"}},"outputId":"5eb6c743-503d-4149-bccb-9fe228e95075"},"source":["model = torchvision.models.resnet18(pretrained=True)\r\n","\r\n","model.fc = Quantumnet()\r\n","\r\n","for param in model.parameters():\r\n","    param.requires_grad = False\r\n","\r\n","# Use CUDA or CPU according to the \"device\" object.\r\n","model = model.to(device)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 147MB/s] \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"bJoWimGqFCWY","executionInfo":{"status":"ok","timestamp":1613666830583,"user_tz":-540,"elapsed":3429,"user":{"displayName":"JOON SUK HUH","photoUrl":"","userId":"03235780383723321017"}}},"source":["model_cut = torchvision.models.resnet18(pretrained=True)\r\n","\r\n","model_cut.fc = Quantumnet_Cut()\r\n","\r\n","for param in model_cut.parameters():\r\n","    param.requires_grad = False\r\n","\r\n","# Use CUDA or CPU according to the \"device\" object.\r\n","model_cut = model_cut.to(device)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"wo5wZ9pfl5rA","executionInfo":{"status":"ok","timestamp":1613666831095,"user_tz":-540,"elapsed":3869,"user":{"displayName":"JOON SUK HUH","photoUrl":"","userId":"03235780383723321017"}}},"source":["model_classical_cut = torchvision.models.resnet18(pretrained=True)\r\n","\r\n","model_classical_cut.fc = Quantumnet_Classical_Cut()\r\n","\r\n","for param in model_classical_cut.parameters():\r\n","    param.requires_grad = False\r\n","\r\n","# Use CUDA or CPU according to the \"device\" object.\r\n","model_classical_cut = model_classical_cut.to(device)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"fVlHzMG781_l","executionInfo":{"status":"ok","timestamp":1613666833665,"user_tz":-540,"elapsed":6329,"user":{"displayName":"JOON SUK HUH","photoUrl":"","userId":"03235780383723321017"}}},"source":["# Load model from file\r\n","path = '/content/drive/MyDrive/Qiskit-Hackathon-Korea/qnn-visualization/'\r\n","\r\n","if quantum:\r\n","    model.load_state_dict(torch.load(\r\n","        path+'quantum_' + filtered_classes[0] + '_' + filtered_classes[1] + '.pt'\r\n","        )\r\n","    )\r\n","                                 \r\n","else:\r\n","    model.load_state_dict(torch.load(\r\n","        path+'classical_' + filtered_classes[0] + '_' + filtered_classes[1] + '.pt'\r\n","        )\r\n","    )"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vtjPTUTnB4WU","executionInfo":{"status":"ok","timestamp":1613666833665,"user_tz":-540,"elapsed":6231,"user":{"displayName":"JOON SUK HUH","photoUrl":"","userId":"03235780383723321017"}},"outputId":"771390c3-fdec-4ab0-f6a2-9881e850d3a0"},"source":["model_dict = model.state_dict()\r\n","\r\n","model_cut_dict = model_cut.state_dict()\r\n","model_cut_dict = {k: v for k, v in model_dict.items() if k in model_cut_dict}\r\n","model_cut.load_state_dict(model_cut_dict)\r\n","\r\n","model_classical_cut_dict = model_classical_cut.state_dict()\r\n","model_classical_cut_dict = {k: v for k, v in model_dict.items() if k in model_classical_cut_dict}\r\n","model_classical_cut.load_state_dict(model_classical_cut_dict)"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"xexZMtUs9Wq-","executionInfo":{"status":"ok","timestamp":1613666833666,"user_tz":-540,"elapsed":6166,"user":{"displayName":"JOON SUK HUH","photoUrl":"","userId":"03235780383723321017"}}},"source":["def dream(image, model, iterations, lr):\r\n","    \"\"\" Updates the image to maximize outputs for n iterations \"\"\"\r\n","    Tensor = torch.cuda.FloatTensor if torch.cuda.is_available else torch.FloatTensor\r\n","    image = preprocess(image).unsqueeze(0).cpu().data.numpy()\r\n","    image = Variable(Tensor(image), requires_grad=True)\r\n","    \r\n","    for i in range(iterations):\r\n","        model.zero_grad()\r\n","        out = model(image)\r\n","        loss = out.norm()\r\n","        if i % 10 == 0:\r\n","            print('iter: {}/{}, loss: {}'.format(i+1, iterations, loss.item()))\r\n","        loss.backward()\r\n","        avg_grad = np.abs(image.grad.data.cpu().numpy()).mean()\r\n","        norm_lr = lr / avg_grad\r\n","        image.data += norm_lr * image.grad.data\r\n","        image.data = clip(image.data)\r\n","        image.grad.data.zero_()\r\n","    return image.cpu().data.numpy()"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"SYDWaas5rtu3","executionInfo":{"status":"ok","timestamp":1613666833666,"user_tz":-540,"elapsed":6076,"user":{"displayName":"JOON SUK HUH","photoUrl":"","userId":"03235780383723321017"}}},"source":["def diff_dream(image, model1, model2, iterations, lr):\r\n","    \"\"\" Updates the image to maximize outputs for n iterations \"\"\"\r\n","    Tensor = torch.cuda.FloatTensor if torch.cuda.is_available else torch.FloatTensor\r\n","    image = preprocess(image).unsqueeze(0).cpu().data.numpy()\r\n","    image = Variable(Tensor(image), requires_grad=True)\r\n","    \r\n","    for i in range(iterations):\r\n","        model1.zero_grad()\r\n","        model2.zero_grad()\r\n","        out1 = model1(image)\r\n","        out2 = model2(image)\r\n","        loss = out1.norm() / np.sqrt(np.prod(out1.shape)) - out2.norm() / np.sqrt(np.prod(out2.shape))\r\n","        if i % 10 == 0:\r\n","            print('iter: {}/{}, loss: {}'.format(i+1, iterations, loss.item()))\r\n","        loss.backward()\r\n","        avg_grad = np.abs(image.grad.data.cpu().numpy()).mean()\r\n","        norm_lr = lr / avg_grad\r\n","        image.data += norm_lr * image.grad.data\r\n","        image.data = clip(image.data)\r\n","        image.grad.data.zero_()\r\n","    return image.cpu().data.numpy()"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q9Lf0Rdz9XOv","executionInfo":{"status":"ok","timestamp":1613666833666,"user_tz":-540,"elapsed":6020,"user":{"displayName":"JOON SUK HUH","photoUrl":"","userId":"03235780383723321017"}}},"source":["def deep_dream(image, model, iterations, lr, octave_scale, num_octaves):\r\n","    \"\"\" Main deep dream method \"\"\"\r\n","    image = preprocess(image).unsqueeze(0).cpu().data.numpy()\r\n","\r\n","    # Extract image representations for each octave\r\n","    octaves = [image]\r\n","    for _ in range(num_octaves - 1):\r\n","        octaves.append(nd.zoom(octaves[-1], (1, 1, 1 / octave_scale, 1 / octave_scale), order=1))\r\n","\r\n","    detail = np.zeros_like(octaves[-1])\r\n","    for octave, octave_base in enumerate(tqdm.tqdm(octaves[::-1], desc=\"Dreaming\")):\r\n","        if octave > 0:\r\n","            # Upsample detail to new octave dimension\r\n","            detail = nd.zoom(detail, np.array(octave_base.shape) / np.array(detail.shape), order=1)\r\n","        # Add deep dream detail from previous octave to new base\r\n","        input_image = octave_base + detail\r\n","        # Get new deep dream image\r\n","        dreamed_image = dream(input_image, model, iterations, lr)\r\n","        # Extract deep dream details\r\n","        detail = dreamed_image - octave_base\r\n","\r\n","    return deprocess(dreamed_image)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"7CM57ZcKKXLb","executionInfo":{"status":"ok","timestamp":1613666833667,"user_tz":-540,"elapsed":5910,"user":{"displayName":"JOON SUK HUH","photoUrl":"","userId":"03235780383723321017"}}},"source":["mean = np.array([0.485, 0.456, 0.406])\r\n","std = np.array([0.229, 0.224, 0.225])\r\n","\r\n","#preprocess = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean, std)])\r\n","preprocess = transforms.Compose([transforms.ToTensor()])\r\n","\r\n","def deprocess(image_np):\r\n","    image_np = image_np.squeeze().transpose(1, 2, 0)\r\n","    image_np = image_np * std.reshape((1, 1, 3)) + mean.reshape((1, 1, 3))\r\n","    image_np = np.clip(image_np, 0.0, 255.0)\r\n","    return image_np\r\n","\r\n","def clip(image_tensor):\r\n","    for c in range(3):\r\n","        m, s = mean[c], std[c]\r\n","        image_tensor[0, c] = torch.clamp(image_tensor[0, c], -m / s, (1 - m) / s)\r\n","    return image_tensor"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1KyyNnXn7PN88UI4pYvHC82LZ_S30HLFK"},"id":"69buln4A9a6U","executionInfo":{"status":"ok","timestamp":1613667194755,"user_tz":-540,"elapsed":366882,"user":{"displayName":"JOON SUK HUH","photoUrl":"","userId":"03235780383723321017"}},"outputId":"6e475eae-5e1c-4bef-94c3-220308ffc322"},"source":["from PIL import Image\r\n","import scipy.ndimage as nd\r\n","from torch.autograd import Variable\r\n","import tqdm, os\r\n","\r\n","# Load image\r\n","image = Image.open(\"/content/drive/MyDrive/Qiskit-Hackathon-Korea/qnn-visualization/images/dog.jpg\")\r\n","\r\n","# Set Models\r\n","#network = model\r\n","#layers = list(network.children())\r\n","\r\n","#classical_model = nn.Sequential(*layers[: 9]) #Max: 9\r\n","classical_model = model_classical_cut\r\n","quantum_model = model_cut\r\n","\r\n","# Extract deep dream image\r\n","dreamed_image = dream(\r\n","        image,\r\n","        quantum_model,\r\n","        iterations=1000,\r\n","        lr=0.01\r\n",")\r\n","\r\n","dreamed_image = np.transpose(dreamed_image, (0,2,3,1))\r\n","dreamed_image = dreamed_image[0]\r\n","\r\n","# Save and plot image\r\n","#os.makedirs(\"outputs\", exist_ok=True)\r\n","#filename = 'test'\r\n","plt.figure(figsize=(20, 20))\r\n","plt.imshow(dreamed_image)\r\n","#plt.imsave(f\"outputs/output_{filename}\", dreamed_image)\r\n","plt.show()"],"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"p3jYm-cJh0-l","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1R1ZbblF3JC6600mY6zkmnZgKQYe4r1E0"},"executionInfo":{"status":"ok","timestamp":1613667563694,"user_tz":-540,"elapsed":735771,"user":{"displayName":"JOON SUK HUH","photoUrl":"","userId":"03235780383723321017"}},"outputId":"8c4e5d30-6638-4492-d784-4561abebafa6"},"source":["quantum_dreamed_image = diff_dream(\r\n","        image,\r\n","        quantum_model,\r\n","        classical_model,\r\n","        iterations=1000,\r\n","        lr=0.01\r\n",")\r\n","\r\n","dreamed_image = quantum_dreamed_image\r\n","\r\n","dreamed_image = np.transpose(dreamed_image, (0,2,3,1))\r\n","dreamed_image = dreamed_image[0]\r\n","\r\n","# Save and plot image\r\n","#os.makedirs(\"outputs\", exist_ok=True)\r\n","#filename = 'test'\r\n","plt.figure(figsize=(20, 20))\r\n","plt.imshow(dreamed_image)\r\n","#plt.imsave(f\"outputs/output_{filename}\", dreamed_image)\r\n","plt.show()"],"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"PUcnnV_emViW","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1AocIUhWUjS5xueGEpqGOiWuJKwBTLl6c"},"executionInfo":{"status":"ok","timestamp":1613667973643,"user_tz":-540,"elapsed":1145631,"user":{"displayName":"JOON SUK HUH","photoUrl":"","userId":"03235780383723321017"}},"outputId":"5baa23cf-0843-4bac-9c6f-ffa433a39f3a"},"source":["classical_dreamed_image = diff_dream(\r\n","        image,\r\n","        classical_model,\r\n","        quantum_model,\r\n","        iterations=1000,\r\n","        lr=0.01\r\n",")\r\n","\r\n","dreamed_image = classical_dreamed_image\r\n","\r\n","dreamed_image = np.transpose(dreamed_image, (0,2,3,1))\r\n","dreamed_image = dreamed_image[0]\r\n","\r\n","# Save and plot image\r\n","#os.makedirs(\"outputs\", exist_ok=True)\r\n","#filename = 'test'\r\n","plt.figure(figsize=(20, 20))\r\n","plt.imshow(dreamed_image)\r\n","#plt.imsave(f\"outputs/output_{filename}\", dreamed_image)\r\n","plt.show()"],"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"y9C1XFE3maVX","executionInfo":{"status":"ok","timestamp":1613667973644,"user_tz":-540,"elapsed":1145494,"user":{"displayName":"JOON SUK HUH","photoUrl":"","userId":"03235780383723321017"}}},"source":[""],"execution_count":22,"outputs":[]}]}